# Gradio Demo Guide

This guide provides instructions on how to run the Gradio demo for JarvisArt.

## Step 1: Installation
1. **Conda Environment:** Set up the conda environment with required dependencies before running the demo.
```bash
conda create -n jarvisart_demo python=3.11
conda activate jarvisart_demo
pip install -r envs/requirements_demo.txt
cd src/sft
pip install -e .
cd ../../dependence/gradio_image_annotator
pip install -e .
cd ../..
```
2. **Install Adobe Lightroom:** Please download and install Adobe Lightroom on your local machine from the [official website](https://www.adobe.com/products/photoshop-lightroom.html). After installation, sign in using your Adobe account credentials.

> **Note:** Adobe Lightroom is a commercial product and may require a subscription or trial account.

## Step 2: Download Preview Model Weights

To run the Gradio demo, you need to download the preview weights from Hugging Face and place them in the correct location:

1. Download the JarvisArt preview weights from [Hugging Face repository](https://huggingface.co/LYL1015/JarvisArt/tree/main/pretrained/preview)
2. Create the weights directory (if it doesn't exist):
   ```bash
   cd JarvisArt/
   mkdir -p ./checkpoints/pretrained/JarvisArt-preview/
   ```
3. Place the downloaded weight files in the `./checkpoints/pretrained/JarvisArt-preview/` directory
4. If you've placed the model weights in a different location, remember to update the `model_name_or_path` parameter in `src/inference/config/qwen2_vl.yaml` to point to your custom model directory.


## Step 3: Running the Gradio Demo

Once the environment is set up and activated, you can run the Gradio demo with the following command from the root directory of the project:

```bash
cd JarvisArt/
bash demo.sh
```
This will launch a web interface at `http://127.0.0.1:7880`.
> **Notes:**
> - Make sure the model path points to a directory containing a valid JarvisArt model with all necessary files.
> - The web interface will be accessible on port 7880 by default.
> - If you want to customize the model path, port, or other parameters, you can configure them in the `demo.sh` script.


## Step 4: Converting Lua to LrTemplate Files

xiUse the `tools/lua2lrt.py` script to convert Lua files (which are generated by the model) into LrTemplate files.
Execute the following command:
```bash
python tools/lua2lrt.py /path/to/your/xxx.lua 
```

> **Note:** 
> - Ensure that your Python environment is properly set up before proceeding.
> - If there are multiple result folders, always use the one with the highest number for the latest output.

## Step 5: Using the Generated LrTemplate Files in Adobe Lightroom

To use the generated `.lrtemplate` files in Adobe Lightroom:

1. Open Adobe Lightroom.
2. Go to the **Presets** panel.
3. Click on the **+** icon.
4. Select **Import Presets**.
5. Choose the `.lrtemplate` file(s) you generated and click **Import**.

The imported presets will now be available in your Presets panel for use on your photos.


